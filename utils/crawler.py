import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime, timedelta
import time
import os
import random
import re

def crawl_xsmb_1ngay_minhchinh_dict(ngay, thang, nam):
    """Crawl 1 ng√†y k·∫øt qu·∫£ XSMB t·ª´ minhchinh.com"""
    date_str = f"{ngay:02d}-{thang:02d}-{nam}"
    url = f"https://www.minhchinh.com/ket-qua-xo-so-mien-bac/{date_str}.html"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    try:
        resp = requests.get(url, headers=headers, timeout=15)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        tables = soup.find_all("table")
        table = None
        for tb in tables:
            trs = tb.find_all("tr")
            if len(trs) > 7 and any('ƒê·∫∑c bi·ªát' in tr.text or 'Nh·∫•t' in tr.text for tr in trs):
                table = tb
                break
        if not table:
            print(f"Kh√¥ng t√¨m th·∫•y b·∫£ng k·∫øt qu·∫£ {date_str}!")
            return None
        result = {"date": f"{nam}-{thang:02d}-{ngay:02d}"}
        for tr in table.find_all("tr"):
            tds = tr.find_all("td")
            if len(tds) < 2: continue
            label = tds[0].get_text(strip=True)
            value = tds[1].get_text(" ", strip=True)
            if "ƒê·∫∑c bi·ªát" in label or "ƒêB" in label:
                match = re.search(r'(\d{5})\b', value)
                result["DB"] = match.group(1) if match else value
            elif "Nh·∫•t" in label:
                result["G1"] = value
            elif "Nh√¨" in label:
                result["G2"] = value
            elif "Ba" in label:
                result["G3"] = value
            elif "T∆∞" in label:
                result["G4"] = value
            elif "NƒÉm" in label:
                result["G5"] = value
            elif "S√°u" in label:
                result["G6"] = value
            elif "B·∫£y" in label:
                result["G7"] = value
        return result
    except Exception as e:
        print(f"‚ùå {date_str}: {e}")
        return None

def crawl_xsmb_Nngay_minhchinh_csv(N=60, out_csv="xsmb.csv", delay_sec=6, use_random_delay=True):
    """
    Crawl N ng√†y XSMB g·∫ßn nh·∫•t, l∆∞u v√†o file CSV (g·ªôp th√™m d·ªØ li·ªáu n·∫øu ƒë√£ c√≥).
    """
    today = datetime.today()
    if os.path.exists(out_csv):
        df_old = pd.read_csv(out_csv)
        days_have = set(str(d) for d in df_old['date'])
    else:
        df_old = None
        days_have = set()
    records = []
    for i in range(1, N+1):  # B·∫Øt ƒë·∫ßu t·ª´ h√¥m qua (i=1)
        date = today - timedelta(days=i)
        date_str = f"{date.year}-{date.month:02d}-{date.day:02d}"
        if date_str in days_have:
            print(f"‚ùé {date.strftime('%d-%m-%Y')} ƒê√É c√≥ trong file, b·ªè qua.")
            continue
        row = crawl_xsmb_1ngay_minhchinh_dict(date.day, date.month, date.year)
        if row:
            records.append(row)
            print(f"‚úîÔ∏è {date.strftime('%d-%m-%Y')} OK, ƒë√£ th√™m m·ªõi.")
        else:
            print(f"‚ùå {date.strftime('%d-%m-%Y')} KH√îNG l·∫•y ƒë∆∞·ª£c!")
        if use_random_delay:
            t = random.uniform(delay_sec*0.7, delay_sec*1.3)
            print(f"‚è≥ ƒê·ª£i {t:.1f} gi√¢y ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
            time.sleep(t)
        else:
            print(f"‚è≥ ƒê·ª£i {delay_sec} gi√¢y ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
            time.sleep(delay_sec)
    # G·ªôp d·ªØ li·ªáu c≈© v√† m·ªõi
    if records:
        df_new = pd.DataFrame(records)
        if df_old is not None:
            df_all = pd.concat([df_old, df_new], ignore_index=True)
        else:
            df_all = df_new
        df_all = df_all.drop_duplicates(subset="date").sort_values("date", ascending=False)
        df_all.to_csv(out_csv, index=False, encoding="utf-8-sig")
        print(f"\nƒê√£ c·∫≠p nh·∫≠t file: {out_csv}. T·ªïng c·ªông {len(df_all)} ng√†y.")
        return df_all
    else:
        print("Kh√¥ng c√≥ ng√†y n√†o m·ªõi ƒë·ªÉ c·∫≠p nh·∫≠t!")
        return df_old if df_old is not None else None

# --- OPTIONAL: H√†m upload l√™n Google Drive (ch·ªâ d√πng cho Colab, kh√¥ng import m·∫∑c ƒë·ªãnh) ---
def upload_csv_to_drive(local_path, remote_name=None, parent_folder_id=None):
    try:
        from pydrive.auth import GoogleAuth
        from pydrive.drive import GoogleDrive
        from google.colab import auth
        from oauth2client.client import GoogleCredentials

        auth.authenticate_user()
        gauth = GoogleAuth()
        gauth.credentials = GoogleCredentials.get_application_default()
        drive = GoogleDrive(gauth)
        if remote_name is None:
            remote_name = os.path.basename(local_path)
        file_drive = drive.CreateFile({
            'title': remote_name,
            'parents': [{"id": parent_folder_id}] if parent_folder_id else []
        })
        file_drive.SetContentFile(local_path)
        file_drive.Upload()
        print(f"‚úÖ ƒê√£ upload {local_path} l√™n Google Drive (t√™n tr√™n Drive: {remote_name})")
        print(f"üëâ Link file: https://drive.google.com/file/d/{file_drive['id']}/view?usp=sharing")
    except Exception as e:
        print(f"‚ùå L·ªói upload l√™n Drive: {e}")

# --- Main entry ch·∫°y ƒë·ªôc l·∫≠p ---
if __name__ == "__main__":
    csv_path = "xsmb.csv"
    crawl_xsmb_Nngay_minhchinh_csv(60, csv_path, delay_sec=6, use_random_delay=True)
    # N·∫øu ch·∫°y tr√™n Colab v√† mu·ªën upload:
    try:
        import google.colab
        parent_folder_id = "YOUR_DRIVE_FOLDER_ID"
        upload_csv_to_drive(csv_path, "xsmb.csv", parent_folder_id)
    except ImportError:
        print("Not running in Colab: Skip Google Drive upload.")
